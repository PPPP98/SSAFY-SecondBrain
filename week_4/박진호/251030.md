## 목표

노트 작성 시 자동으로 임베딩 벡터를 생성하고, 유사도 기반으로 노트 간 관계를 연결하여 개인 지식을 그래프 형태로 구축하는 시스템을 개발합니다. 핵심은 사용자가 별도 작업 없이 노트를 작성하면 시스템이 자동으로 연관 노트를 발견하고 연결하는 것

- 수동 태그나 링크 없이 **자동으로 노트 간 의미적 연결 발견**
- 잊고 있던 과거 노트와 새 노트의 연관성 파악
- 지식의 네트워크 효과를 통한 통찰력 향상

### **시스템 아키텍처 설계**

**1. 노트 저장 계층 (PostgreSQL)**

- 사용자가 작성한 노트의 원본 데이터를 저장합니다
- 제목, 본문, 작성일시, 수정일시, 임베딩 처리 상태를 관리합니다
- 빠른 CRUD 작업과 전문 검색을 위한 인덱스를 구축합니다

**2. 지식 그래프 계층 (Neo4j)**

- 노트와 청크를 노드로, 관계를 엣지로 표현합니다
- 벡터 인덱스를 통해 유사도 검색을 수행합니다
- 그래프 순회로 N-hop 관계를 탐색합니다

**3. 비동기 처리 계층 (RabbitMQ)**

- 노트 저장과 임베딩 생성을 분리하여 응답 속도를 보장합니다
- 워커 프로세스가 큐에서 작업을 가져와 처리합니다
- 실패한 작업은 재시도 로직으로 복구합니다

## 데이터 흐름

1. 사용자가 노트를 작성하여 API로 전송
2. API 서버가 PostgreSQL에 즉시 저장하고 응답 반환
3. 동시에 RabbitMQ에 임베딩 작업 메시지 발행
4. 워커가 메시지를 수신하여 청크 분할 및 임베딩 생성
5. 생성된 임베딩을 Neo4j에 저장
6. 유사 노트를 검색하여 관계 생성
7. PostgreSQL의 임베딩 상태를 '완료'로 업데이트

---

## 고려했던 사항

노트 지식 그래프를 구축하면서 가장 고민했던 부분은 어떻게 노트를 임베딩할 것인가였다. 처음에는 RAG 시스템에서 흔히 사용하는 청크 기반 접근을 고려했다. 노트를 500 토큰 단위로 나누고 각 청크마다 개별 임베딩을 생성하면 긴 노트에서도 정보 손실 없이 세밀한 유사도 계산이 가능하다는 장점이 있었다. 특히 2000 토큰이 넘는 긴 문서에서도 특정 부분끼리의 유사성을 정확히 포착할 수 있고, 향후 하이브리드 검색이나 RAG 기반 질의응답으로 확장하기에도 유리했다.

하지만 이 방식은 Neo4j 그래프가 복잡해진다는 문제가 있었다. Chunk 노드가 수천 개 생겨나면 시각화도 어렵고, 사용자 입장에서 "노트 간 연결"을 직관적으로 이해하기 힘들어진다. 또한 임베딩을 노트 전체로 할지 Summary로 할지도 고민이었다. Summary를 사용하면 짧아서 처리가 빠르지만, LLM으로 요약을 생성하는 추가 비용과 시간이 들고 무엇보다 세부 내용과 맥락이 사라져 간접적인 연결고리를 놓칠 수 있었다. 결국 본문 전체를 사용하기로 했지만, 청크로 나눌지 통째로 임베딩할지는 계속 고민이었다.

개인 노트의 실제 길이 분포를 생각해보니 대부분은 1000-1500 토큰 이하였다. 한글 기준으로 1500 토큰이면 A4 1.5장 정도로, 일반적인 메모나 학습 노트 대부분이 이 범위에 들어온다. 정말 긴 문서는 전체의 10-20% 정도에 불과할 것 같았다. 그렇다면 80-90%를 위해 전체 시스템을 복잡하게 만드는 것보다, 단순한 방식으로 시작해서 필요할 때 확장하는 것이 MVP 철학에 맞다는 생각이 들었다.

## 지금 선택의 이유

결국 1차 MVP에서는 노트 하나를 하나의 노드로, 노트 전체를 단일 임베딩으로 처리하기로 결정했다. 이 선택의 가장 큰 이유는 단순성과 직관성이다. 사용자 입장에서 "노트 = 노드"라는 개념은 설명 없이도 이해할 수 있고, 그래프를 봤을 때 자연스럽다. Chunk 노드가 수백 개 섞여 있으면 오히려 혼란스러울 것이다.

구현 측면에서도 4주 안에 완성 가능한 현실적인 범위다. 1500 토큰 이하 노트는 전체를 그대로 임베딩하고, 그 이상은 처음 1500 토큰만 잘라서 사용하기로 했다. 긴 노트의 뒷부분이 유사도 계산에 반영되지 않는다는 단점은 있지만, 일반적으로 노트 앞부분에 핵심 내용이 있고 실제로 긴 노트는 소수이기 때문에 큰 문제가 되지 않을 것 같다. 옵션으로 청크로 나눠서 평균 임베딩을 사용할 수도 있지만, 우선은 잘라내기 방식으로 시작한다.

무엇보다 이 방식은 향후 전환이 가능하다는 점이 중요하다. 실제 사용해보고 긴 노트의 정보 손실이 심각하거나 유사도 정확도가 떨어진다면, 그때 청크 기반으로 마이그레이션하면 된다. API는 그대로 유지하고 내부 구현만 바꾸면 되니 사용자 입장에서는 변화를 느끼지 못할 것이다. 완벽한 시스템을 처음부터 만들려고 하기보다, 핵심 가치인 "자동 노트 연결"을 빠르게 검증하는 것이 MVP의 목표다.

## 1차 MVP 이후 개선사항

MVP 이후 가장 먼저 개선할 부분은 긴 노트 처리 방식이다. 실사용 데이터를 보고 2000 토큰 이상 노트가 30% 이상이거나 유사도 정확도가 60% 미만으로 떨어지면, 청크 기반 시스템으로 전환한다. 백그라운드에서 기존 노트들을 500 토큰씩 청킹하고 각각 임베딩을 생성한 뒤, Top-3 청크 평균 유사도로 노트 간 관계를 재계산한다. 이때 Neo4j에 Chunk 노드를 추가하되 UI에서는 여전히 Note 노드만 보여주면 된다. 필요시 "왜 이 노트들이 연결됐는지" 물어볼 때만 매칭된 청크 정보를 제공하면 설명 가능성도 확보된다.

두 번째는 하이브리드 검색 도입이다. 현재는 벡터 유사도만 사용하지만, BM25 키워드 검색을 추가하면 전문 용어나 고유명사 매칭 정확도가 크게 향상된다. 특히 "Neo4j"나 "GraphDB" 같은 특정 용어가 들어간 노트끼리는 키워드로 정확히 매칭하고, 의미적으로 유사한 "그래프 데이터베이스"는 벡터로 찾아낸 뒤, Reciprocal Rank Fusion으로 두 결과를 결합하면 10-20% 정확도 개선이 예상된다. 사용자 피드백 루프도 추가해서, 제안된 연결에 대해 "유용함/관련없음"을 표시하면 그 데이터로 임계값을 동적으로 조정하거나 특정 노트 쌍을 차단할 수 있다.

장기적으로는 시맨틱 클러스터링과 RAG 질의응답으로 발전시킬 수 있다. 임베딩 공간에서 노트들을 자동으로 클러스터링해서 "머신러닝", "프로젝트 관리" 같은 주제별 그룹을 만들면, 사용자가 자신의 지식 분포를 한눈에 파악할 수 있다. 그리고 "GraphDB에서 벡터 검색은 어떻게 하지?"라고 질문하면, 유사한 노트 5개를 찾아 컨텍스트로 구성하고 LLM이 답변하되 출처 노트를 명시하는 방식으로 개인 지식 기반 질의응답이 가능해진다. 하지만 이 모든 것은 1차 MVP로 기본 가치를 검증한 후에 단계적으로 추가할 계획이다.